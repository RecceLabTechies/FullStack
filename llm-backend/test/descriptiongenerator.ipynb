{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_datetime64_any_dtype, is_numeric_dtype, is_object_dtype\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Return JSON's Headers and Description of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return JSON's Headers and Description of Data\n",
    "\n",
    "- Tells LLM what files are available and what headers are in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: ./Data/Adjusted_Ad_Campaign_Performance_Data.json\n",
      "Headers:\n",
      "  Time\n",
      "  Campaign_ID\n",
      "  Age_group\n",
      "  Channel_Name\n",
      "  Spending\n",
      "  Number_of_Views\n",
      "  Number_of_Leads\n",
      "----------------------------------------\n",
      "\n",
      "File: ./Data/Banking_KPI_Data.json\n",
      "Headers:\n",
      "  Time\n",
      "  Number_of_New_Accounts\n",
      "  Total_Base_Mn\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def extract_headers(file_path):\n",
    "    \"\"\"\n",
    "    Extract headers from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        list: List of headers from the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    headers = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # For a dictionary, get the keys\n",
    "        headers = list(data.keys())\n",
    "    elif isinstance(data, list) and data:\n",
    "        first_item = data[0]\n",
    "        if isinstance(first_item, dict):\n",
    "            # For a list of dictionaries, get the keys from the first item\n",
    "            headers = list(first_item.keys())\n",
    "\n",
    "    return headers\n",
    "\n",
    "\n",
    "def recursive_json_schema_extractor(directory):\n",
    "    \"\"\"\n",
    "    Recursively walks through the given directory and extracts headers\n",
    "    from all JSON files found.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): The root directory to start the recursive search.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping JSON file paths to their header lists\n",
    "    \"\"\"\n",
    "    schemas = {}\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            # Recursively process subdirectories\n",
    "            schemas.update(recursive_json_schema_extractor(full_path))\n",
    "        elif entry.lower().endswith(\".json\"):\n",
    "            try:\n",
    "                headers = extract_headers(full_path)\n",
    "                schemas[full_path] = headers\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {full_path}: {e}\")\n",
    "    return schemas\n",
    "\n",
    "\n",
    "# Extract headers from all JSON files\n",
    "data_dir = \"./Data\"\n",
    "json_schemas = recursive_json_schema_extractor(data_dir)\n",
    "\n",
    "# Print the results\n",
    "for file_path, headers in json_schemas.items():\n",
    "    print(f\"\\nFile: {file_path}\")\n",
    "    print(\"Headers:\")\n",
    "    for header in headers:\n",
    "        print(f\"  {header}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relevant columns:\n",
      "- Adjusted_Ad_Campaign_Performance_Data.json: Spending\n",
      "- Adjusted_Ad_Campaign_Performance_Data.json: Number_of_Views\n"
     ]
    }
   ],
   "source": [
    "# Format json_schemas into a readable string for the prompt (without type info)\n",
    "def format_schemas_for_prompt(schemas):\n",
    "    formatted_str = \"\"\n",
    "    for file_path, headers in schemas.items():\n",
    "        file_name = os.path.basename(file_path)  # Get just the filename without path\n",
    "        # Assume headers is now a list; join just the header names.\n",
    "        headers_str = \", \".join(headers)\n",
    "        formatted_str += f\"{file_name}: [{headers_str}]\\n\"\n",
    "    return formatted_str\n",
    "\n",
    "\n",
    "# Pydantic model for column selection\n",
    "class ColumnSelections(BaseModel):\n",
    "    selections: list[tuple[str, str]]  # List of (filename, column) pairs\n",
    "\n",
    "\n",
    "# Template for column selection\n",
    "template = \"\"\"Given the following JSON file headers and their data types, determine which columns would be relevant to answer the query.\n",
    "\n",
    "Available JSON files and their headers (with types):\n",
    "{json_headers}\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Respond only with a list of [filename, column] pairs, one per line, in this exact format:\n",
    "[file1.json, column1]\n",
    "[file1.json, column2]\n",
    "[file2.json, column3]\n",
    "...etc\n",
    "\n",
    "Each pair should be unique and relevant to the query.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "\n",
    "# Function to parse LLM output into ColumnSelections\n",
    "def parse_llm_response(response: str) -> ColumnSelections:\n",
    "    lines = response.strip().split(\"\\n\")\n",
    "    selections = []\n",
    "    seen_pairs = set()  # To ensure uniqueness\n",
    "\n",
    "    for line in lines:\n",
    "        # Remove brackets and split by comma\n",
    "        clean_line = line.strip(\"[]\").split(\",\")\n",
    "        if len(clean_line) == 2:\n",
    "            filename = clean_line[0].strip()\n",
    "            column = clean_line[1].strip()\n",
    "            pair = (filename, column)\n",
    "\n",
    "            # Only add if we haven't seen this combination before\n",
    "            if pair not in seen_pairs:\n",
    "                selections.append(pair)\n",
    "                seen_pairs.add(pair)\n",
    "\n",
    "    return ColumnSelections(selections=selections)\n",
    "\n",
    "\n",
    "# Create the chain with structured output\n",
    "chain = prompt | model | parse_llm_response\n",
    "\n",
    "# Example usage with json_schemas:\n",
    "formatted_headers = format_schemas_for_prompt(json_schemas)\n",
    "result = chain.invoke(\n",
    "    {\"json_headers\": formatted_headers, \"query\": \"Show me the revenue trends\"}\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nRelevant columns:\")\n",
    "for filename, column in result.selections:\n",
    "    print(f\"- {filename}: {column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"filename\": \"Adjusted_Ad_Campaign_Performance_Data.json\",\n",
      "        \"column\": \"Spending\",\n",
      "        \"statistics\": {\n",
      "            \"Count\": 14068,\n",
      "            \"Missing Values\": 0,\n",
      "            \"Mean\": 0.40944839351720214,\n",
      "            \"Median\": 0.23,\n",
      "            \"Mode\": 0.02,\n",
      "            \"Std Dev\": 0.5067380156190855,\n",
      "            \"Min\": 0.0,\n",
      "            \"Max\": 6.45,\n",
      "            \"Q1 (25th percentile)\": 0.08,\n",
      "            \"Q3 (75th percentile)\": 0.56,\n",
      "            \"IQR\": 0.48000000000000004\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"filename\": \"Adjusted_Ad_Campaign_Performance_Data.json\",\n",
      "        \"column\": \"Number_of_Views\",\n",
      "        \"statistics\": {\n",
      "            \"Count\": 14068,\n",
      "            \"Missing Values\": 0,\n",
      "            \"Mean\": 200.9016917827694,\n",
      "            \"Median\": 109.0,\n",
      "            \"Mode\": 1,\n",
      "            \"Std Dev\": 270.0523566422892,\n",
      "            \"Min\": 0,\n",
      "            \"Max\": 6472,\n",
      "            \"Q1 (25th percentile)\": 36.0,\n",
      "            \"Q3 (75th percentile)\": 271.0,\n",
      "            \"IQR\": 235.0\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\"\n",
    "    Custom JSON Encoder that converts numpy data types\n",
    "    into native Python types so they can be serialized.\n",
    "    \"\"\"\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def collect_statistics_report(result: ColumnSelections) -> list:\n",
    "    \"\"\"\n",
    "    Collects comprehensive statistical report data for selected columns,\n",
    "    returning a JSON-serializable list of statistics per (filename, column) pair.\n",
    "\n",
    "    Parameters:\n",
    "        result (ColumnSelections): The Pydantic model containing the list of (filename, column) pairs.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries with detailed statistics for each selected column.\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    for filename, column in result.selections:\n",
    "        try:\n",
    "            # Read the JSON file\n",
    "            df = pd.read_json(f\"./Data/{filename}\")\n",
    "\n",
    "            if pd.api.types.is_numeric_dtype(df[column]):\n",
    "                stats = {\n",
    "                    \"Count\": df[column].count(),\n",
    "                    \"Missing Values\": df[column].isnull().sum(),\n",
    "                    \"Mean\": df[column].mean(),\n",
    "                    \"Median\": df[column].median(),\n",
    "                    \"Mode\": (\n",
    "                        df[column].mode().iloc[0]\n",
    "                        if not df[column].mode().empty\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"Std Dev\": df[column].std(),\n",
    "                    \"Min\": df[column].min(),\n",
    "                    \"Max\": df[column].max(),\n",
    "                    \"Q1 (25th percentile)\": df[column].quantile(0.25),\n",
    "                    \"Q3 (75th percentile)\": df[column].quantile(0.75),\n",
    "                    \"IQR\": df[column].quantile(0.75) - df[column].quantile(0.25),\n",
    "                }\n",
    "            else:\n",
    "                # For categorical columns, calculate unique count, missing values, and frequency counts.\n",
    "                value_counts = df[column].value_counts().to_dict()\n",
    "                stats = {\n",
    "                    \"Unique Values\": df[column].nunique(),\n",
    "                    \"Missing Values\": df[column].isnull().sum(),\n",
    "                    \"Value Frequencies\": value_counts,\n",
    "                }\n",
    "        except Exception as e:\n",
    "            stats = {\"error\": str(e)}\n",
    "\n",
    "        report.append({\"filename\": filename, \"column\": column, \"statistics\": stats})\n",
    "    return report\n",
    "\n",
    "\n",
    "# Example usage: Store the statistics in a JSON-serializable data structure.\n",
    "stats_report = collect_statistics_report(result)\n",
    "\n",
    "# Convert the report to a JSON string using the custom NumpyEncoder.\n",
    "stats_report_json = json.dumps(stats_report, indent=4, cls=NumpyEncoder)\n",
    "print(stats_report_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Comprehensive Summary of the JSON Statistics Report**\n",
      "\n",
      "The provided JSON statistics report contains information on two columns: \"Spending\" and \"Number of Views\". Both columns have identical statistical characteristics, such as counts, missing values, means, medians, modes, standard deviations, minimums, maximums, quartiles, and interquartile ranges (IQR). This suggests that the data is consistent across both columns.\n",
      "\n",
      "**Key Insights:**\n",
      "\n",
      "1. **Consistency across columns**: The identical statistical characteristics of both columns indicate a high degree of consistency in the data.\n",
      "2. **Large number of observations**: Both columns have 14,068 observations, which is a significant sample size and should provide reliable insights into the underlying phenomena.\n",
      "3. **Presence of missing values**: Neither column has any missing values, which indicates that the data is complete and free from errors.\n",
      "\n",
      "**Trends:**\n",
      "\n",
      "1. **Skewed distribution**: The \"Spending\" column follows a skewed distribution with a higher frequency at lower values (mode = 0.02), while the \"Number of Views\" column also exhibits skewness but with a broader range of values.\n",
      "2. **Increasing trend in spending**: Although not statistically significant, there appears to be an increasing trend in spending from minimum value (0) to maximum value (6.45).\n",
      "\n",
      "**Anomalies:**\n",
      "\n",
      "1. **High variability in \"Number of Views\"**: The standard deviation of 270.0523566422892 for the \"Number of Views\" column is unusually high, indicating a significant amount of variation or outliers in this data.\n",
      "2. **Wide range of values in both columns**: Both columns exhibit a wide range of values, which may indicate variability in the underlying phenomena being measured.\n",
      "\n",
      "**Additional Observations:**\n",
      "\n",
      "1. **Insufficient information for regression analysis**: Due to the limited data and absence of additional information (e.g., dates), it is challenging to perform regression analysis or other statistical tests that require more context.\n",
      "2. **Need for further investigation**: The anomalies in the \"Number of Views\" column, particularly the high variability, may indicate a need for further investigation into the underlying factors driving this phenomenon.\n",
      "\n",
      "In conclusion, while the data exhibits some consistency and trends across both columns, there are also notable anomalies that warrant further attention and analysis.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Based on the following JSON statistics report for various columns, generate a comprehensive written summary of the findings.\n",
    "\n",
    "JSON Statistics Report:\n",
    "{stats_report}\n",
    "\n",
    "Please provide a detailed summary including key insights, trends, and any anomalies in the data.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "chain = prompt | model\n",
    "final_report = chain.invoke({\"stats_report\": stats_report_json})\n",
    "\n",
    "print(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt4103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
