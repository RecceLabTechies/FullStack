{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "%pip install -U langchain-ollama\n",
    "%pip install langchain.prompts\n",
    "%pip install langchain_community\n",
    "%pip install langchain_community.llms\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_datetime64_any_dtype, is_numeric_dtype, is_object_dtype\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Return JSON's Headers and Description of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return JSON's Headers and Description of Data\n",
    "\n",
    "- Tells LLM what files are available and what headers are in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def extract_headers(file_path):\n",
    "    \"\"\"\n",
    "    Extract headers from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        list: List of headers from the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    headers = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # For a dictionary, get the keys\n",
    "        headers = list(data.keys())\n",
    "    elif isinstance(data, list) and data:\n",
    "        first_item = data[0]\n",
    "        if isinstance(first_item, dict):\n",
    "            # For a list of dictionaries, get the keys from the first item\n",
    "            headers = list(first_item.keys())\n",
    "\n",
    "    return headers\n",
    "\n",
    "\n",
    "def recursive_json_schema_extractor(directory):\n",
    "    \"\"\"\n",
    "    Recursively walks through the given directory and extracts headers\n",
    "    from all JSON files found.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): The root directory to start the recursive search.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping JSON file paths to their header lists\n",
    "    \"\"\"\n",
    "    schemas = {}\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            # Recursively process subdirectories\n",
    "            schemas.update(recursive_json_schema_extractor(full_path))\n",
    "        elif entry.lower().endswith(\".json\"):\n",
    "            try:\n",
    "                headers = extract_headers(full_path)\n",
    "                schemas[full_path] = headers\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {full_path}: {e}\")\n",
    "    return schemas\n",
    "\n",
    "\n",
    "# Extract headers from all JSON files\n",
    "data_dir = \"./Data\"\n",
    "json_schemas = recursive_json_schema_extractor(data_dir)\n",
    "\n",
    "# Print the results\n",
    "for file_path, headers in json_schemas.items():\n",
    "    print(f\"\\nFile: {file_path}\")\n",
    "    print(\"Headers:\")\n",
    "    for header in headers:\n",
    "        print(f\"  {header}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation Creator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the file and columns to create the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Pydantic model for chart information\n",
    "class ChartInfo(BaseModel):\n",
    "    file_name: str\n",
    "    x_axis: str\n",
    "    y_axis: str\n",
    "\n",
    "\n",
    "# Format json_schemas into a readable string for the prompt (without type info)\n",
    "def format_schemas_for_prompt(schemas):\n",
    "    formatted_str = \"\"\n",
    "    for file_path, headers in schemas.items():\n",
    "        file_name = os.path.basename(file_path)  # Get just the filename without path\n",
    "        # Assume headers is now a list; join just the header names.\n",
    "        headers_str = \", \".join(headers)\n",
    "        formatted_str += f\"{file_name}: [{headers_str}]\\n\"\n",
    "    return formatted_str\n",
    "\n",
    "\n",
    "# Template that includes instructions for the LLM\n",
    "template = \"\"\"Given the following JSON file headers, determine the most appropriate file and columns to create the visualization.\n",
    "\n",
    "Available JSON files and their headers:\n",
    "{json_headers}\n",
    "\n",
    "Chart request: {query}\n",
    "\n",
    "Respond only with the following information in this exact format:\n",
    "file_name: [selected json file name]\n",
    "x_axis: [column name for x-axis]\n",
    "y_axis: [column name for y-axis]\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "\n",
    "# Function to parse LLM output into ChartInfo\n",
    "def parse_llm_response(response: str) -> ChartInfo:\n",
    "    lines = response.strip().split(\"\\n\")\n",
    "    parsed = {}\n",
    "    for line in lines:\n",
    "        key, value = line.split(\": \")\n",
    "        parsed[key] = value.strip()\n",
    "\n",
    "    return ChartInfo(**parsed)\n",
    "\n",
    "\n",
    "# Create the chain with structured output\n",
    "chain = prompt | model | parse_llm_response\n",
    "\n",
    "# Example usage with json_schemas:\n",
    "formatted_headers = format_schemas_for_prompt(json_schemas)\n",
    "result = chain.invoke(\n",
    "    {\"json_headers\": formatted_headers, \"query\": \"Show me the revenue trends over time\"}\n",
    ")\n",
    "\n",
    "print(\"Selected file:\", result.file_name)\n",
    "print(\"X-axis:\", result.x_axis)\n",
    "print(\"Y-axis:\", result.y_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe for selected file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(f\"./Data/{result.file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Chart Generator\n",
    "\n",
    "1. Properly imports all necessary data type checking functions from pandas\n",
    "2. Handles different data type combinations:\n",
    "    - Time series data (both datetime and string-based time columns)\n",
    "    - Numeric vs numeric (scatter plots)\n",
    "    - Categorical vs numeric (box plots)\n",
    "    - Categorical vs categorical (heatmaps)\n",
    "3. Includes automatic handling of:\n",
    "    - Label rotation for better readability\n",
    "    - Layout adjustments to prevent cutoff\n",
    "    - Proper sorting for time series data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(df: pd.DataFrame, x_col: str, y_col: str) -> None:\n",
    "    \"\"\"\n",
    "    Generate an appropriate visualization based on the data types of input columns.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "        x_col (str): Column name for x-axis\n",
    "        y_col (str): Column name for y-axis\n",
    "    \"\"\"\n",
    "    # Set figure size and style\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Determine data types\n",
    "    x_is_datetime = is_datetime64_any_dtype(df[x_col])\n",
    "    x_is_numeric = is_numeric_dtype(df[x_col])\n",
    "    x_is_categorical = is_object_dtype(df[x_col])\n",
    "\n",
    "    y_is_datetime = is_datetime64_any_dtype(df[y_col])\n",
    "    y_is_numeric = is_numeric_dtype(df[y_col])\n",
    "    y_is_categorical = is_object_dtype(df[y_col])\n",
    "\n",
    "    # Time series plot\n",
    "    if x_is_datetime and y_is_numeric:\n",
    "        sns.lineplot(data=df, x=x_col, y=y_col)\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "    # Scatter plot for numeric vs numeric\n",
    "    elif x_is_numeric and y_is_numeric:\n",
    "        sns.scatterplot(data=df, x=x_col, y=y_col)\n",
    "\n",
    "    # Box plot for categorical vs numeric\n",
    "    elif x_is_categorical and y_is_numeric:\n",
    "        sns.boxplot(data=df, x=x_col, y=y_col)\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "    # Bar plot for categorical vs numeric (alternative to box plot)\n",
    "    elif y_is_categorical and x_is_numeric:\n",
    "        sns.barplot(data=df, x=x_col, y=y_col)\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "    # Heatmap for categorical vs categorical\n",
    "    elif x_is_categorical and y_is_categorical:\n",
    "        # Create contingency table\n",
    "        contingency = pd.crosstab(df[x_col], df[y_col])\n",
    "        sns.heatmap(contingency, annot=True, fmt=\"d\", cmap=\"YlOrRd\")\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported combination of data types\")\n",
    "\n",
    "    # Add labels and adjust layout\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(f\"{y_col} vs {x_col}\")\n",
    "    plt.tight_layout()  # Prevent label cutoff\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_graph(df, result.x_axis, result.y_axis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt4103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
